{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:14:12.169335Z",
     "start_time": "2021-09-10T08:14:11.581178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from helper_functions import mkdirifnotexists\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import re\n",
    "import statsmodels\n",
    "from datetime import datetime\n",
    "\n",
    "curr_dir = mkdirifnotexists(os.path.join('preprocess_metabolon_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T07:45:30.717901Z",
     "start_time": "2021-09-10T07:45:27.879603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/wisdom/python-3.7.4/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "acs_data = pd.read_csv('data/ACS_full_data.csv', index_col=0)\n",
    "pnp_data = pd.read_csv('data/pnp1_full_data.csv', index_col='RegistrationCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metabolon_may18_retired_unknows = os.path.join('additional_metabolon_files', 'WEIZ-01-18ML+ CDT retired unknowns 060618.xlsx')\n",
    "_metabolon_mar20_retired_unknows = os.path.join('additional_metabolon_files', 'WEIZ-01-16ML+ and WEIZ-01-18ML+ Retired compounds.csv')\n",
    "\n",
    "_metabolon_columns = ['SAMPLE_ID', 'SAMPLE_NAME', 'CLIENT_IDENTIFIER', 'BARCODE', 'BATCH', 'GROUP_NUMBER',\n",
    "                      'COMMENT', 'StudyTypeID', 'RegistrationCode', 'StorageDT']\n",
    "\n",
    "# Updates regarding molecules (Mar 2019)\n",
    "_molecule_name_update_mar2019 = {'X - 12230': '4-ethylcatechol sulfate',\n",
    "                                 'X - 12329': '3-hydroxy-2-methylpyridine sulfate',\n",
    "                                 'X - 12837': 'glucuronide of C19H28O4 (2)*',\n",
    "                                 'X - 14662': 'glycoursodeoxycholate sulfate (1)',\n",
    "                                 'X - 16654': 'deoxycholic acid (12 or 24)-sulfate*',\n",
    "                                 'X - 17145': 'branched chain 14:0 dicarboxylic acid**',\n",
    "                                 'X - 17469': 'lithocholic acid sulfate (1)',\n",
    "                                 'X - 18249': '3,5-dichloro-2,6-dihydroxybenzoic acid',\n",
    "                                 'X - 18914': '3-bromo-5-chloro-2,6-dihydroxybenzoic acid*',\n",
    "                                 'X - 23649': '3-hydroxypyridine glucuronide'}\n",
    "# comments regarding molecules (Mar 2019)\n",
    "_molecule_comment_update_mar2019 = {'X - 11315': 'elucidation in progress; may be an amino acid derivative',\n",
    "                                    'X - 11640': 'has been named for enterolactone sulfate as of earlier this month',\n",
    "                                    'X - 11843': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 11850': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12126': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12216': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12261': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12283': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12718': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 12738': 'candidate structure is phenol-related',\n",
    "                                    'X - 13835': 'candidate structure is an aromatic amino acid related metabolite',\n",
    "                                    'X - 13844': 'candidate structure is a benzoic acid derivative',\n",
    "                                    'X - 17185': 'candidate structure is phenol-related',\n",
    "                                    'X - 17354': 'candidate structure is polyphenol related',\n",
    "                                    'X - 21286': 'candidate structure is pyridine related',\n",
    "                                    'X - 22509': 'candidate structure is polyphenol related',\n",
    "                                    'X - 22520': 'fatty acid conjugate',\n",
    "                                    'X - 23639': \"high priority internally, but don'left have a good guess right now\",\n",
    "                                    'X - 23655': 'candidate structure is pyridine related',\n",
    "                                    'X - 24243': 'candidate structure is piperidine related',\n",
    "                                    'X - 24410': 'candidate structure is piperidine related'}\n",
    "\n",
    "\n",
    "# metabolomics_names = Defs.load_list('metabolomics_names')\n",
    "\n",
    "\n",
    "def _update_molecule_comment_and_name_mar2019(metabs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param metabs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # update names\n",
    "    metabs = metabs.replace({'BIOCHEMICAL': _molecule_name_update_mar2019})\n",
    "    metabs['COMMENT'] = metabs['BIOCHEMICAL'].copy()\n",
    "    # add comments\n",
    "    metabs = metabs.replace({'COMMENT': _molecule_comment_update_mar2019})\n",
    "    return metabs\n",
    "\n",
    "def _update_retired_molecules_data(metabs):\n",
    "    retired = pd.read_csv(_metabolon_mar20_retired_unknows, index_col=0)\n",
    "    metabs_intersection = list(set(metabs.index).intersection(set(retired.index)))\n",
    "\n",
    "    # for c in ['SUPER_PATHWAY', 'SUB_PATHWAY', 'BIOCHEMICAL']:\n",
    "    for c in ['SUPER_PATHWAY', 'SUB_PATHWAY']:\n",
    "        metabs.loc[metabs_intersection, c] = retired.loc[metabs_intersection, c]\n",
    "    return metabs\n",
    "\n",
    "def _load_may18_retired_unknows():\n",
    "    metabolon_may18_retired_unknows = pd.read_excel(_metabolon_may18_retired_unknows, 'OrigScale',\n",
    "                                                          header=None, engine='openpyxl')\n",
    "    metabolon_may18_retired_unknows = metabolon_may18_retired_unknows.loc[\n",
    "        metabolon_may18_retired_unknows[7].notnull()]\n",
    "    metabolon_may18_retired_unknows_dic = {\n",
    "        re.compile('(X - [0-9]+)').search(str(metabolon_may18_retired_unknows.loc[i, 7])).\n",
    "            group(1): metabolon_may18_retired_unknows.loc[i, 6] for i in\n",
    "        metabolon_may18_retired_unknows.index}\n",
    "    return metabolon_may18_retired_unknows, metabolon_may18_retired_unknows_dic\n",
    "\n",
    "def _load_metabolomics():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    metabolon_may18_retired_unknows, metabolon_may18_retired_unknows_dic = _load_may18_retired_unknows()\n",
    "\n",
    "    data_mar17 = pd.read_excel('Serum_metabolomics.xlsx', 'raw data') # EGAD00001006247\n",
    "    samples_mar17 = pd.read_excel('Serum_metabolomics.xlsx', 'sample metadata') # EGAD00001006247\n",
    "    metabs_mar17 = pd.read_excel('Serum_metabolomics.xlsx', 'metabolite metadata') # EGAD00001006247\n",
    "    \n",
    "    data_may18 = pd.read_excel('metabolon_data.xlsx', 'Raw data') # EGAS00001005342\n",
    "    samples_may18 = pd.read_excel('metabolon_data.xlsx', 'Sample metadata') # EGAS00001005342\n",
    "    metabs_may18 = pd.read_excel('metabolon_data.xlsx', 'Metabolites') # EGAS00001005342\n",
    "    \n",
    "    data_list = [data_mar17, data_may18]\n",
    "    samples_list = [samples_mar17, samples_may18]\n",
    "    metabs_list = [metabs_mar17, metabs_may18]\n",
    "\n",
    "    data = pd.concat(data_list, sort=True, axis=0)\n",
    "    samples = pd.concat(samples_list, sort=True, axis=0)\n",
    "    metabs = pd.concat(metabs_list, sort=True, axis=0)\n",
    "    # remove retired molecules\n",
    "    metabs = metabs[~metabs.index.isin(metabolon_may18_retired_unknows_dic.keys())]\n",
    "    metabs = _update_molecule_comment_and_name_mar2019(metabs)\n",
    "    # update retired unknowns (MAR 2020)\n",
    "    metabs = _update_retired_molecules_data(metabs)\n",
    "    metabs.SUPER_PATHWAY.fillna('Unknowns', inplace=True)\n",
    "    metabs.SUB_PATHWAY.fillna('Unknowns', inplace=True)\n",
    "\n",
    "    # TODO: perhaps a better solution would be to keep a row for each CHEMICAL_ID, and then columns of data from\n",
    "    #  each run the compound appears in\n",
    "    metabs = metabs.reset_index().groupby('CHEMICAL_ID').apply(lambda x: x.loc[x.metabolon_run_id.idxmax()]) \\\n",
    "        .drop('CHEMICAL_ID', axis=1)\n",
    "    return data, samples, metabs\n",
    "\n",
    "def _normalize_within_run_using_anchors(df, samples):\n",
    "    \"\"\"\n",
    "    For each run, normalize each column by the anchor sample of that inner run batch.\n",
    "    This will leave you only with columns which have non-zero values for all anchor samples across the the run.\n",
    "    In case of multiple anchor samples in the same batch the mean will be considered for normalizing.\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    normed_data = []\n",
    "    for run_id in samples.metabolon_run.unique():\n",
    "        run_samples = samples[samples.metabolon_run == run_id]\n",
    "        normed_data.append(MetabolonLoader._per_run_anchor_normalization(df.loc[run_samples.index.dropna()],\n",
    "                                                                         run_samples))\n",
    "    return pd.concat(normed_data, sort=True)\n",
    "\n",
    "def _per_run_anchor_normalization(run_df, run_samples):\n",
    "    \"\"\"\n",
    "\n",
    "    :param run_df:\n",
    "    :param run_samples:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    col_names = run_df.columns.names\n",
    "    anchor_ids = run_samples[run_samples.COMMENT == 'Anchor_sample'].index\n",
    "    anchor_data = run_df.loc[anchor_ids].copy()\n",
    "    # in case there is more than one anchor in batch take their mean\n",
    "    index_name = anchor_data.index.names[0]\n",
    "    anc_mean_per_metabolite_per_batch = anchor_data.reset_index().merge(run_samples.reset_index()\n",
    "                                                                        [[index_name, 'BATCH']],\n",
    "                                                                        on=index_name).groupby('BATCH') \\\n",
    "        .apply(np.mean).dropna(axis=1)\n",
    "    anc_median_per_metabolite = anchor_data[anc_mean_per_metabolite_per_batch.columns].median()\n",
    "    # keep only metabs to be normalize and add the batch as index\n",
    "    normed_data = run_df[anc_mean_per_metabolite_per_batch.columns].reset_index().merge(\n",
    "        run_samples.reset_index()[[index_name, 'BATCH']], on=index_name).set_index(['BATCH', index_name]).copy()\n",
    "    #  for each metabolite m: m * (Anchor(median) / Anchor(batch))\n",
    "    norm_factor = 1. / anc_mean_per_metabolite_per_batch.loc[normed_data.index.get_level_values('BATCH')].values\n",
    "    norm_factor *= anc_median_per_metabolite.values\n",
    "    normed_data = normed_data * norm_factor\n",
    "    normed_data = normed_data.reset_index().set_index(index_name)\n",
    "    del normed_data['BATCH']\n",
    "    # for other compounds, transform to presence absence\n",
    "    normed_data.columns.names = col_names\n",
    "    return normed_data\n",
    "\n",
    "def _normalize_across_runs_using_anchors(df, samples, normalize_std, log_transform_base, min_num_of_anc_per_run=5):\n",
    "    \"\"\"\n",
    "    Normalizing the samples across the Metabolon runs using the anchor samples.\n",
    "    First consider only columns which have non missing values in at least min_num_of_anc_per_run anchor samples\n",
    "    within each run.\n",
    "    Then apply log transformation.\n",
    "    For each metabolite compute the median of anchor samples within each run, and multiply all samples of each run\n",
    "    with the median of anchors across all runs divided by the median of anchors within that run.\n",
    "    Next divide the samples by the std of the anchor samples within each run. Optional.\n",
    "    :param df:\n",
    "    :param samples:\n",
    "    :param normalize_std:\n",
    "    :param min_num_of_anc_per_run:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # find list of metabolites which can be normalized\n",
    "    common_metabs = df.notnull().sum() > min_num_of_anc_per_run\n",
    "    for run_id in samples.metabolon_run.unique():\n",
    "        anchor_samples = samples[(samples.metabolon_run == run_id) & (samples.COMMENT == 'Anchor_sample')].index\n",
    "        common_metabs = common_metabs & (df.loc[anchor_samples].notnull().sum() > min_num_of_anc_per_run)\n",
    "    normed_data = df.loc[:, common_metabs]\n",
    "\n",
    "    # take log of data\n",
    "    if log_transform_base is None: log_transform_base = 10\n",
    "    normed_data = MetabolonLoader._log_transform(normed_data, log_transform_base)\n",
    "\n",
    "    # compute median of anchor samples (Mi) for each run, and std of anchors for each run (STDi)\n",
    "    median_anchor_per_run = {run_id: normed_data.loc[\n",
    "        samples[(samples.metabolon_run == run_id) & (samples.COMMENT == 'Anchor_sample')].index].median()\n",
    "                             for run_id in samples.metabolon_run.unique()}\n",
    "    std_anchor_per_run = {run_id: normed_data.loc[\n",
    "        samples[(samples.metabolon_run == run_id) & (samples.COMMENT == 'Anchor_sample')].index].std()\n",
    "                          for run_id in samples.metabolon_run.unique()}\n",
    "\n",
    "    # for each run i with data Xi, perform Xi -= Mi)\n",
    "    normed_data_list = []\n",
    "    for run_id in samples.metabolon_run.unique():\n",
    "        run_samples = samples[samples.metabolon_run == run_id].index\n",
    "        normed_data_list.append(normed_data.loc[run_samples] - median_anchor_per_run[run_id])\n",
    "    normed_data = pd.concat(normed_data_list, sort=True)\n",
    "\n",
    "    # for each run i with data Xi, perform Xi /= STDi\n",
    "    if normalize_std:\n",
    "        normed_data_list = []\n",
    "        for run_id in samples.metabolon_run.unique():\n",
    "            run_samples = samples[samples.metabolon_run == run_id].index\n",
    "            normed_data_list.append(normed_data.loc[run_samples] / std_anchor_per_run[run_id])\n",
    "        normed_data = pd.concat(normed_data_list, sort=True)\n",
    "\n",
    "    return normed_data\n",
    "\n",
    "def _fill_missing_values_with_min(df):\n",
    "    return df.fillna(df.min())\n",
    "\n",
    "def _log_transform(df, logbase):\n",
    "    if logbase is None: return df\n",
    "    logbases = {10: np.log10, 2: np.log2, 'natural': np.log}\n",
    "    if logbase not in logbases:\n",
    "        print('Please provide a valid base for the log:', ', '.join(logbases.keys()))\n",
    "        exit\n",
    "    return df.apply(logbases[logbase])\n",
    "\n",
    "def _robust_zs(df, robust_zs):\n",
    "    if robust_zs is None: return df\n",
    "    df_tmp = df.clip(lower=df.quantile(.05), upper=df.quantile(.95), axis=1)\n",
    "    return ((df - df.median()) / df_tmp.std())\n",
    "\n",
    "def _clip_outliers(df, n_stds, clip_or_na='clip'):\n",
    "    if n_stds is None: return df\n",
    "    if clip_or_na not in ['clip', 'na']:\n",
    "        print('clip_or_na must be one of ' + ', '.join(['clip', 'na']))\n",
    "        return None\n",
    "    for c in df.columns:\n",
    "        outlier_th = n_stds * df[c].std()\n",
    "        df_mean = df[c].mean()\n",
    "        if df[c].unique().shape[0] < 5:\n",
    "            continue\n",
    "        if clip_or_na == 'na':\n",
    "            is_outlier = np.abs(df[c] - df_mean) > outlier_th\n",
    "            if np.sum(is_outlier) > 0: df.loc[is_outlier, c] = np.nan\n",
    "        if clip_or_na == 'clip':\n",
    "            is_upper_outlier = df[c] - df_mean > outlier_th\n",
    "            if np.sum(is_upper_outlier) > 0: df.loc[is_upper_outlier, c] = df_mean + outlier_th\n",
    "            is_lower_outlier = df_mean - df[c] > outlier_th\n",
    "            if np.sum(is_lower_outlier) > 0: df.loc[is_lower_outlier, c] = df_mean - outlier_th\n",
    "    return df\n",
    "\n",
    "\n",
    "    def get_data(metabolon_runs=None, robust_zs=None, clip_outliers_std=None,\n",
    "                 clip_outliers_or_na='clip', fill_missing_with_min=None, log_transform_base=None,\n",
    "                 norm_within_run_using_anchors=None, norm_across_run_using_anchors=None, normalize_std=None):\n",
    "        \"\"\"\n",
    "        Retrieves serum metabolomics data with various filters by metadata and normalization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metabolon_runs : str or list, optional\n",
    "            List of metabolon runs. e.g. Metabolon_MAY2018, Metabolon_MAR2017\n",
    "        robust_zs : bool, optional\n",
    "            Whether to perform robust standardization\n",
    "        clip_outliers_std : bool, optional\n",
    "            Whether to clip outliers\n",
    "        fill_missing_with_min : bool, optional\n",
    "            Fill missing values with global minimal value per column.\n",
    "        log_transform_base : int, optional\n",
    "            Perform log transformation with this base.\n",
    "        norm_within_run_using_anchors : bool, optional\n",
    "            Normalize metabolites using anchor samples with in each metabolomics run (details in implementation).\n",
    "            Will only return metabolites which are present in all anchor samples (subset).\n",
    "        norm_across_run_using_anchors : bool, optional\n",
    "            Normalize metabolites using anchor samples across runs.\n",
    "            Will only return metabolites which are common to all requested runs (subset).\n",
    "        normalize_std : bool, optional\n",
    "            In case normalizing across runs, whether to also normalize by the variance of the anchor samples.\n",
    ":\n",
    "        Returns\n",
    "        -------\n",
    "        df : serum metabolomics after normalization and filtering.\n",
    "        df_metadata : metadata about the samples in the metabolomics runs.\n",
    "        metabolites : metadata about the metabolites (columns of df). Metabolite index is CHEMICAL_ID.\n",
    "\n",
    "        \"\"\"\n",
    "        df, metadata, metabs = _load_metabolomics()\n",
    "        \n",
    "        if norm_within_run_using_anchors:\n",
    "            df = _normalize_within_run_using_anchors(df, metadata)\n",
    "            normalize_std = None\n",
    "\n",
    "        _log_transformed = False\n",
    "        if norm_across_run_using_anchors:\n",
    "            df = _normalize_across_runs_using_anchors(df, metadata, normalize_std, log_transform_base)\n",
    "            _log_transformed = True\n",
    "\n",
    "        if not _log_transformed and log_transform_base:\n",
    "            df = _log_transform(df, logbase=log_transform_base)\n",
    "        df = _robust_zs(df, robust_zs=robust_zs)\n",
    "        df = _clip_outliers(df, n_stds=clip_outliers_std, clip_or_na=clip_outliers_or_na)\n",
    "        \n",
    "        if fill_missing_with_min: \n",
    "            df = _fill_missing_values_with_min(df)\n",
    "        \n",
    "        return df, metadata, metabolites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T07:46:25.830964Z",
     "start_time": "2021-09-10T07:46:22.404586Z"
    }
   },
   "outputs": [],
   "source": [
    "df, metadata, metabolites = get_data(robust_zs=True, clip_outliers_std=5, clip_outliers_or_na='clip', \n",
    "                                     fill_missing_with_min=True, log_transform_base=10, norm_within_run_using_anchors=None, \n",
    "                                     norm_across_run_using_anchors=True, normalize_std=True)\n",
    "\n",
    "# these data are merged with the clinical and other data and saved separatley as pnp_data_metabolon.csv and acs_data_metabolon.csv\n",
    "\n",
    "# df[metadata['StudyTypeID'] == 'non-ACS'].join(pnp_data).to_csv('data/pnp_data_metabolon.csv')\n",
    "# df[metadata['StudyTypeID'] == 'ACS'].join(acs_data).to_csv('data/acs_data_metabolon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:18:54.180024Z",
     "start_time": "2021-09-10T08:18:50.902746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/wisdom/python-3.7.4/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (43,3236,3261) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/wisdom/python-3.7.4/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (1,11,24,31,41,97,108,111,112,113,132,133,134,135,136,137,138,139,140,141,142,143,144,146,149,150,151,152,153,154,156,158,160,170,171,180,185,3213) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pnp_data_metabolon = pd.read_csv('pnp_data_metabolon.csv', index_col=0)\n",
    "acs_data_metabolon = pd.read_csv('acs_data_metabolon.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:37:05.440582Z",
     "start_time": "2021-09-10T08:37:04.336810Z"
    }
   },
   "outputs": [],
   "source": [
    "common_pnp1_reg_id = set(pnp_data_metabolon.dropna(subset=['100000007']).index).intersection(set(metabolon.df_metadata.RegistrationCode.astype(int)))\n",
    "metabolon_df = metabolon.df.copy()\n",
    "metabolon_df.set_index(metabolon.df_metadata.loc[metabolon_df.index].RegistrationCode.astype(int).values, inplace=True)\n",
    "\n",
    "pnp_data_metabolon_v2.loc[common_pnp1_reg_id, metabolon_df.columns] = metabolon_df.loc[common_pnp1_reg_id, metabolon_df.columns].values\n",
    "pnp_data_metabolon_v2.loc[382562, metabolon_df.columns] = np.nan\n",
    "\n",
    "metabolon_acs_reg_id = acs_data_metabolon_v3.dropna(subset=['100000007']).index\n",
    "acs_data_metabolon_v3.loc[metabolon_acs_reg_id, metabolon_df.columns] = metabolon_df.loc[metabolon_acs_reg_id, metabolon_df.columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# days since storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:37:10.623192Z",
     "start_time": "2021-09-10T08:37:10.172602Z"
    }
   },
   "outputs": [],
   "source": [
    "pnp1_may18 = metadata[(metadata.StudyTypeID == 'non-ACS') & (metadata.metabolon_run == 'Metabolon_MAY2018')]['RegistrationCode'].astype(int).values\n",
    "\n",
    "pnp1_mar17 = list(set(pnp_data_metabolon.dropna(subset=['100000007']).index) - set(pnp1_may18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:37:46.694066Z",
     "start_time": "2021-09-10T08:37:46.577004Z"
    }
   },
   "outputs": [],
   "source": [
    "pnp_data_metabolon.loc[pnp1_mar17, 'days_since_storage'] = [x.days for x in pd.to_datetime('01/03/2017', dayfirst=True) - \n",
    "                                                               pd.to_datetime(pnp_data_metabolon.loc[pnp1_mar17, 'Date'])]\n",
    "pnp_data_metabolon.loc[pnp1_may18, 'days_since_storage'] = [x.days for x in pd.to_datetime('01/05/2018', dayfirst=True) - \n",
    "                                                               pd.to_datetime(pnp_data_metabolon.loc[pnp1_may18, 'Date'])]\n",
    "acs_data_metabolon['days_since_storage'] = [x.days for x in pd.to_datetime('01/05/2018', dayfirst=True) - \n",
    "                                               pd.to_datetime(acs_data_metabolon['SerumStorageDate'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:37:50.244045Z",
     "start_time": "2021-09-10T08:37:49.851728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   0.,   0.,   0.,   5.,  72.,  44., 144., 123.,  54.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,  26.,   1.],\n",
       "        [  1.,  52.,  55.,  46.,   2.,   0.,   0.,   0.,   0.,   0.]]),\n",
       " array([ -93. ,   50.1,  193.2,  336.3,  479.4,  622.5,  765.6,  908.7,\n",
       "        1051.8, 1194.9, 1338. ]),\n",
       " <a list of 3 BarContainer objects>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([pnp_data_metabolon.loc[pnp1_mar17, 'days_since_storage'], \n",
    "          pnp_data_metabolon.loc[pnp1_may18, 'days_since_storage'],\n",
    "          acs_data_metabolon['days_since_storage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T16:15:28.171650Z",
     "start_time": "2021-09-15T16:15:28.114462Z"
    }
   },
   "outputs": [],
   "source": [
    "pnp_data_metabolon['const'] = 1\n",
    "acs_data_metabolon['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T16:15:32.349539Z",
     "start_time": "2021-09-15T16:15:29.889927Z"
    }
   },
   "outputs": [],
   "source": [
    "pnp_data_metabs = pnp_data_metabolon.loc[:, metabolites.index].dropna()\n",
    "min_values = pnp_data_metabs.round(5).min()\n",
    "metabs_with_missing_values = (pnp_data_metabs.round(5) == min_values).sum() > 1\n",
    "pnp_data_metabs[pnp_data_metabs.round(5) == min_values] = np.nan\n",
    "acs_data_metabs = acs_data_metabolon.loc[:, metabolites.index].dropna()\n",
    "acs_data_metabs[acs_data_metabs.round(5) == min_values] = np.nan\n",
    "\n",
    "mostly_missing_metabs = pnp_data_metabs.notnull().sum().sort_values()[pnp_data_metabs.notnull().sum().sort_values() < 100].index\n",
    "\n",
    "pnp_mar17_data = pnp_data_metabolon.loc[pnp1_mar17].copy()\n",
    "pnp_mar17_data.loc[pnp1_mar17, metabolites.index] = pnp_data_metabs.loc[pnp1_mar17, :].values\n",
    "pnp_may18_data = pnp_data_metabolon.loc[pnp1_may18].copy()\n",
    "pnp_may18_data.loc[pnp1_may18, metabolites.index] = pnp_data_metabs.loc[pnp1_may18, :].values\n",
    "acs_may18_data = acs_data_metabolon.copy()\n",
    "acs_may18_data.loc[acs_data_metabs.index, metabolites.index] = acs_data_metabs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T16:15:35.544804Z",
     "start_time": "2021-09-15T16:15:35.338315Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((pnp_mar17_data, pnp_may18_data, acs_may18_data), axis=0).loc[:, metabolites.index].dropna(how='all', axis=0)\n",
    "\n",
    "covariates = ['Age']\n",
    "pnp_mar17_x = pnp_data_metabolon.loc[pnp1_mar17, ['days_since_storage', 'const'] + covariates]\n",
    "pnp_mar17_x['cohort'] = 'control_mar17'\n",
    "pnp_may18_x = pnp_data_metabolon.loc[pnp1_may18, ['days_since_storage', 'const']]\n",
    "pnp_may18_x['cohort'] = 'control_may18'\n",
    "acs_may18_x = acs_data_metabolon.dropna(subset=['100000007']).loc[:, ['days_since_storage', 'const']]\n",
    "acs_may18_x['cohort'] = 'acs_may18'\n",
    "\n",
    "all_x = pd.concat((pnp_mar17_x, pnp_may18_x, acs_may18_x), axis=0).dropna(how='all', axis=0)\n",
    "all_x = pd.concat((all_x.drop('cohort', axis=1), pd.get_dummies(all_x['cohort'])), axis=1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_x[['days_since_storage']])\n",
    "all_x['days_since_storage'] = scaler.transform(all_x[['days_since_storage']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T16:15:38.758100Z",
     "start_time": "2021-09-15T16:15:38.701178Z"
    }
   },
   "outputs": [],
   "source": [
    "storage_bad_metabs = pd.read_pickle(os.path.join('data/storage_time_bad_metabs_bonf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T16:16:04.666014Z",
     "start_time": "2021-09-15T16:16:00.272033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [00:04<00:00, 214.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "storage_bad_metabs_new = []\n",
    "coefs = []\n",
    "pvals = []\n",
    "for c in tqdm(set(metabolites.index) - set(mostly_missing_metabs) - set(storage_bad_metabs)):\n",
    "\n",
    "    ols = OLS(all_data[c], all_x.astype(float), missing='drop')\n",
    "    res = ols.fit()\n",
    "    \n",
    "    coef = res.params.loc['days_since_storage']\n",
    "    pval = res.pvalues.loc['days_since_storage']\n",
    "    coefs.append(coef)\n",
    "    pvals.append(pval)\n",
    "    \n",
    "    if pval < 0.05:\n",
    "        pnp_mar17_data.loc[pnp_mar17_x.index, c] -= (coef * all_x.loc[pnp_mar17_x.index, 'days_since_storage'])\n",
    "        pnp_may18_data.loc[pnp_may18_x.index, c] -= (coef * all_x.loc[pnp_may18_x.index, 'days_since_storage'])\n",
    "        acs_may18_data.loc[acs_may18_x.index, c] -= (coef * all_x.loc[acs_may18_x.index, 'days_since_storage'])\n",
    "    \n",
    "print((np.array(pvals) < 0.05).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:44:58.236671Z",
     "start_time": "2021-09-10T08:44:57.101108Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_data = pd.concat((pnp_mar17_data, pnp_may18_data, acs_may18_data.loc[acs_may18_x.index]), axis=0).loc[:, metabolites.index]\n",
    "merged_data.fillna(merged_data.min(), inplace=True)\n",
    "\n",
    "pnp_mar17_data.loc[:, metabolites.index] = merged_data.loc[pnp_mar17_x.index].values\n",
    "pnp_may18_data.loc[:, metabolites.index] = merged_data.loc[pnp_may18_x.index].values\n",
    "acs_may18_data.loc[acs_may18_x.index, metabolites.index] = merged_data.loc[acs_may18_x.index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T08:45:08.576823Z",
     "start_time": "2021-09-10T08:44:59.967551Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat((pnp_mar17_data, pnp_may18_data), axis=0).to_csv(os.path.join('data/pnp_data_metabolon_storage_residuals.csv'))\n",
    "acs_may18_data.to_csv(os.path.join('data/acs_data_metabolon_storage_residuals.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "742.117px",
    "left": "0px",
    "right": "1548px",
    "top": "110.883px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
